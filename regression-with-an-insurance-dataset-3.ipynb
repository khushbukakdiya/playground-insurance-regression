{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4a1d84",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-16T22:42:12.445557Z",
     "iopub.status.busy": "2024-12-16T22:42:12.444716Z",
     "iopub.status.idle": "2024-12-16T22:42:13.152442Z",
     "shell.execute_reply": "2024-12-16T22:42:13.151560Z"
    },
    "papermill": {
     "duration": 0.713061,
     "end_time": "2024-12-16T22:42:13.154389",
     "exception": false,
     "start_time": "2024-12-16T22:42:12.441328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/playground-series-s4e12/sample_submission.csv\n",
      "/kaggle/input/playground-series-s4e12/train.csv\n",
      "/kaggle/input/playground-series-s4e12/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd650f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:42:13.159905Z",
     "iopub.status.busy": "2024-12-16T22:42:13.159533Z",
     "iopub.status.idle": "2024-12-16T22:42:22.732860Z",
     "shell.execute_reply": "2024-12-16T22:42:22.731451Z"
    },
    "papermill": {
     "duration": 9.578147,
     "end_time": "2024-12-16T22:42:22.734918",
     "exception": false,
     "start_time": "2024-12-16T22:42:13.156771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna-integration[lightgbm]\r\n",
      "  Downloading optuna_integration-4.1.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from optuna-integration[lightgbm]) (4.0.0)\r\n",
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (from optuna-integration[lightgbm]) (4.2.0)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from optuna-integration[lightgbm]) (1.2.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightgbm->optuna-integration[lightgbm]) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm->optuna-integration[lightgbm]) (1.14.1)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->optuna-integration[lightgbm]) (1.13.3)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->optuna-integration[lightgbm]) (6.8.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna->optuna-integration[lightgbm]) (21.3)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna->optuna-integration[lightgbm]) (2.0.30)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna->optuna-integration[lightgbm]) (4.66.4)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna->optuna-integration[lightgbm]) (6.0.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->optuna-integration[lightgbm]) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->optuna-integration[lightgbm]) (3.5.0)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (1.3.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (4.12.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna->optuna-integration[lightgbm]) (3.1.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->optuna-integration[lightgbm]) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (2.1.5)\r\n",
      "Downloading optuna_integration-4.1.0-py3-none-any.whl (97 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: optuna-integration\r\n",
      "Successfully installed optuna-integration-4.1.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna-integration[lightgbm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2164afb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:42:22.742455Z",
     "iopub.status.busy": "2024-12-16T22:42:22.742140Z",
     "iopub.status.idle": "2024-12-16T22:42:35.228674Z",
     "shell.execute_reply": "2024-12-16T22:42:35.227697Z"
    },
    "papermill": {
     "duration": 12.492404,
     "end_time": "2024-12-16T22:42:35.230463",
     "exception": false,
     "start_time": "2024-12-16T22:42:22.738059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (1200000, 21)\n",
      "Test Data Shape: (800000, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMTunerCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load datasets\n",
    "df_train = pd.read_csv('/kaggle/input/playground-series-s4e12/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/playground-series-s4e12/test.csv')\n",
    "sample_sub = pd.read_csv('/kaggle/input/playground-series-s4e12/sample_submission.csv')\n",
    "\n",
    "# Inspect datasets\n",
    "print(\"Train Data Shape:\", df_train.shape)\n",
    "print(\"Test Data Shape:\", df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7a49ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:42:35.237164Z",
     "iopub.status.busy": "2024-12-16T22:42:35.236899Z",
     "iopub.status.idle": "2024-12-16T22:42:44.769494Z",
     "shell.execute_reply": "2024-12-16T22:42:44.768751Z"
    },
    "papermill": {
     "duration": 9.53823,
     "end_time": "2024-12-16T22:42:44.771504",
     "exception": false,
     "start_time": "2024-12-16T22:42:35.233274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save test IDs for submission\n",
    "test_ids = df_test['id']\n",
    "\n",
    "# Drop 'id' columns from train and test datasets\n",
    "df_train.drop(columns=['id'], inplace=True)\n",
    "df_test.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Extract date features\n",
    "def create_date_features(df):\n",
    "    df['Policy Start Date'] = pd.to_datetime(df['Policy Start Date'])\n",
    "    df['Year'] = df['Policy Start Date'].dt.year\n",
    "    df['Month'] = df['Policy Start Date'].dt.month\n",
    "    df['Day'] = df['Policy Start Date'].dt.day\n",
    "    df['Day_of_Week'] = df['Policy Start Date'].dt.dayofweek\n",
    "\n",
    "    # Cyclical features\n",
    "    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)\n",
    "    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "    df['Day_sin'] = np.sin(2 * np.pi * df['Day'] / 31)\n",
    "    df['Day_cos'] = np.cos(2 * np.pi * df['Day'] / 31)\n",
    "\n",
    "    df.drop(columns=['Policy Start Date'], inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train = create_date_features(df_train)\n",
    "df_test = create_date_features(df_test)\n",
    "\n",
    "# Add custom features\n",
    "def add_custom_features(df):\n",
    "    df['contract_length'] = pd.cut(\n",
    "        df['Insurance Duration'].fillna(99),\n",
    "        bins=[-float('inf'), 1, 3, float('inf')],\n",
    "        labels=[0, 1, 2]\n",
    "    ).astype(int)\n",
    "    return df\n",
    "\n",
    "df_train = add_custom_features(df_train)\n",
    "df_test = add_custom_features(df_test)\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns.drop('Premium Amount')\n",
    "categorical_cols = df_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "df_train[numerical_cols] = imputer_num.fit_transform(df_train[numerical_cols])\n",
    "df_test[numerical_cols] = imputer_num.transform(df_test[numerical_cols])\n",
    "\n",
    "df_train[categorical_cols] = imputer_cat.fit_transform(df_train[categorical_cols])\n",
    "df_test[categorical_cols] = imputer_cat.transform(df_test[categorical_cols])\n",
    "\n",
    "# Frequency encode categorical features\n",
    "def frequency_encoding(train, test, columns):\n",
    "    for col in columns:\n",
    "        freq_map = train[col].value_counts().to_dict()\n",
    "        train[col] = train[col].map(freq_map)\n",
    "        test[col] = test[col].map(freq_map)\n",
    "    return train, test\n",
    "\n",
    "df_train, df_test = frequency_encoding(df_train, df_test, categorical_cols)\n",
    "\n",
    "# Log-transform features\n",
    "df_train['Annual Income'] = np.log1p(df_train['Annual Income'])\n",
    "df_test['Annual Income'] = np.log1p(df_test['Annual Income'])\n",
    "\n",
    "# Log-transform the target variable\n",
    "y = np.log1p(df_train['Premium Amount'])\n",
    "X = df_train.drop(columns=['Premium Amount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce9f535e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:42:44.777885Z",
     "iopub.status.busy": "2024-12-16T22:42:44.777646Z",
     "iopub.status.idle": "2024-12-16T22:49:42.207672Z",
     "shell.execute_reply": "2024-12-16T22:49:42.206795Z"
    },
    "papermill": {
     "duration": 417.446525,
     "end_time": "2024-12-16T22:49:42.220877",
     "exception": false,
     "start_time": "2024-12-16T22:42:44.774352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-16 22:42:44,781] A new study created in memory with name: no-name-d617360f-3668-44c4-92ba-f77f10842afe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1031\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.027899 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.593848\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1033\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.043402 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.594073\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1031\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.035261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.592481\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.028637 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.594598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1032\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.027012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.594444\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-16 22:43:55,725] Trial 0 finished with value: 0.15920257552804845 and parameters: {'n_estimators': 579, 'learning_rate': 0.065201181842362, 'max_depth': 4, 'num_leaves': 295, 'min_child_samples': 27, 'subsample': 0.7138252090325714, 'colsample_bytree': 0.9283248461518304, 'reg_alpha': 0.022386805215316607, 'reg_lambda': 0.06010828839566318}. Best is trial 0 with value: 0.15920257552804845.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1031\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.026241 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.593848\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1033\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.028707 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.594073\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1031\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.040243 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.592481\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.026379 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.594598\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1032\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.026562 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.594444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-16 22:47:01,919] Trial 1 finished with value: 0.15914181279070372 and parameters: {'n_estimators': 1410, 'learning_rate': 0.06067502507670206, 'max_depth': 8, 'num_leaves': 70, 'min_child_samples': 26, 'subsample': 0.8607210279367381, 'colsample_bytree': 0.7897998437008988, 'reg_alpha': 0.0060563352933326545, 'reg_lambda': 0.005718586915585909}. Best is trial 1 with value: 0.15914181279070372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1031\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.027113 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.593848\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1033\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.028351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.594073\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1031\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.025920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.592481\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.026008 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.594598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1032\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (25.63 MB) transferred to GPU in 0.025920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.594444\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-16 22:49:42,203] Trial 2 finished with value: 0.16036028441823338 and parameters: {'n_estimators': 634, 'learning_rate': 0.1593420797578512, 'max_depth': 9, 'num_leaves': 254, 'min_child_samples': 15, 'subsample': 0.6446974614249471, 'colsample_bytree': 0.8916462961358764, 'reg_alpha': 1.6684663707493057, 'reg_lambda': 0.01769003152775274}. Best is trial 1 with value: 0.15914181279070372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 1410, 'learning_rate': 0.06067502507670206, 'max_depth': 8, 'num_leaves': 70, 'min_child_samples': 26, 'subsample': 0.8607210279367381, 'colsample_bytree': 0.7897998437008988, 'reg_alpha': 0.0060563352933326545, 'reg_lambda': 0.005718586915585909}\n"
     ]
    }
   ],
   "source": [
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 15),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 300),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10),\n",
    "        'device': 'gpu'  # Change to 'cpu' if GPU causes issues\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_log_error')\n",
    "    rmsle = np.mean(np.sqrt(-cv_scores))\n",
    "    return rmsle\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=3)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64a0562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:49:42.242557Z",
     "iopub.status.busy": "2024-12-16T22:49:42.242307Z",
     "iopub.status.idle": "2024-12-16T22:51:32.980299Z",
     "shell.execute_reply": "2024-12-16T22:51:32.979291Z"
    },
    "papermill": {
     "duration": 110.751609,
     "end_time": "2024-12-16T22:51:32.982831",
     "exception": false,
     "start_time": "2024-12-16T22:49:42.231222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1029\n",
      "[LightGBM] [Info] Number of data points in the train set: 1200000, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 6.593889\n"
     ]
    }
   ],
   "source": [
    "# Train final LightGBM model with best parameters\n",
    "final_model = lgb.LGBMRegressor(**best_params)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Predict on test data\n",
    "test_preds = np.expm1(final_model.predict(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23a9587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T22:51:33.009096Z",
     "iopub.status.busy": "2024-12-16T22:51:33.008778Z",
     "iopub.status.idle": "2024-12-16T22:51:34.358744Z",
     "shell.execute_reply": "2024-12-16T22:51:34.357786Z"
    },
    "papermill": {
     "duration": 1.363053,
     "end_time": "2024-12-16T22:51:34.360525",
     "exception": false,
     "start_time": "2024-12-16T22:51:32.997472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Prepare submission file\n",
    "submission = pd.DataFrame({'id': test_ids, 'Premium Amount': test_preds})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10305135,
     "sourceId": 84896,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 564.993625,
   "end_time": "2024-12-16T22:51:34.990188",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-16T22:42:09.996563",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
